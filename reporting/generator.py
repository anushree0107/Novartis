"""Report Generator - Auto-generated clinical trial reports."""
import os
from typing import Dict, List, Optional, Any
from dataclasses import dataclass, field
from datetime import datetime
from enum import Enum
import networkx as nx


class ReportType(Enum):
    SITE_SUMMARY = "site_summary"
    STUDY_OVERVIEW = "study_overview"
    WEEKLY_DIGEST = "weekly_digest"
    EXECUTIVE_SUMMARY = "executive_summary"
    DQI_REPORT = "dqi_report"
    ALERT_SUMMARY = "alert_summary"


@dataclass
class ReportSection:
    """Individual section of a report."""
    title: str
    content: str
    section_type: str = "text"
    data: Optional[Dict] = None


@dataclass
class Report:
    """Complete generated report."""
    report_id: str
    report_type: ReportType
    title: str
    
    entity_type: str
    entity_id: str
    
    generated_at: datetime = field(default_factory=datetime.now)
    period_start: Optional[datetime] = None
    period_end: Optional[datetime] = None
    
    sections: List[ReportSection] = field(default_factory=list)
    
    executive_summary: str = ""
    key_findings: List[str] = field(default_factory=list)
    recommendations: List[str] = field(default_factory=list)
    
    raw_data: Dict[str, Any] = field(default_factory=dict)
    
    def to_markdown(self) -> str:
        lines = [
            f"# {self.title}",
            "",
            f"**Report Type:** {self.report_type.value}",
            f"**Entity:** {self.entity_type.title()} {self.entity_id}",
            f"**Generated:** {self.generated_at.strftime('%Y-%m-%d %H:%M')}",
            "",
        ]
        
        if self.period_start and self.period_end:
            lines.append(f"**Period:** {self.period_start.strftime('%Y-%m-%d')} to {self.period_end.strftime('%Y-%m-%d')}")
            lines.append("")
        
        lines.append("---")
        lines.append("")
        
        if self.executive_summary:
            lines.append("## Executive Summary")
            lines.append("")
            lines.append(self.executive_summary)
            lines.append("")
        
        if self.key_findings:
            lines.append("## Key Findings")
            lines.append("")
            for finding in self.key_findings:
                lines.append(f"- {finding}")
            lines.append("")
        
        for section in self.sections:
            lines.append(f"## {section.title}")
            lines.append("")
            lines.append(section.content)
            lines.append("")
        
        if self.recommendations:
            lines.append("## Recommendations")
            lines.append("")
            for i, rec in enumerate(self.recommendations, 1):
                lines.append(f"{i}. {rec}")
            lines.append("")
        
        lines.append("---")
        lines.append(f"*Report generated by SAGE-Flow Clinical Intelligence Platform*")
        
        return "\n".join(lines)
    
    def to_dict(self) -> Dict[str, Any]:
        return {
            "report_id": self.report_id,
            "report_type": self.report_type.value,
            "title": self.title,
            "entity_type": self.entity_type,
            "entity_id": self.entity_id,
            "generated_at": self.generated_at.isoformat(),
            "executive_summary": self.executive_summary,
            "key_findings": self.key_findings,
            "recommendations": self.recommendations,
            "sections": [
                {"title": s.title, "content": s.content, "type": s.section_type}
                for s in self.sections
            ]
        }


class ReportGenerator:
    """
    Enterprise Report Generator.
    
    Features:
    - Template-based report generation
    - Multi-format output (Markdown, JSON)
    - LLM-enhanced summaries
    - Automated insights extraction
    """
    
    def __init__(self, graph: nx.DiGraph, dqi_calculator=None, benchmark_engine=None, 
                 ranking_engine=None, alert_engine=None, llm=None):
        self.graph = graph
        self.dqi_calculator = dqi_calculator
        self.benchmark_engine = benchmark_engine
        self.ranking_engine = ranking_engine
        self.alert_engine = alert_engine
        self.llm = llm
        self._report_counter = 0
        self._init_llm()
    
    def _init_llm(self):
        if self.llm is None:
            try:
                from langchain_groq import ChatGroq
                self.llm = ChatGroq(
                    model="qwen/qwen3-32b",
                    temperature=0.3,
                    groq_api_key=os.getenv("GROQ_API_KEY")
                )
            except Exception:
                self.llm = None
    
    def _generate_report_id(self) -> str:
        self._report_counter += 1
        return f"RPT-{datetime.now().strftime('%Y%m%d%H%M')}-{self._report_counter:04d}"
    
    def generate_site_summary(self, site_id: str) -> Report:
        """Generate comprehensive site summary report."""
        report = Report(
            report_id=self._generate_report_id(),
            report_type=ReportType.SITE_SUMMARY,
            title=f"Site Summary Report: {site_id}",
            entity_type="site",
            entity_id=site_id
        )
        
        site_data = self._get_site_data(site_id)
        report.raw_data = site_data
        
        dqi_section = self._generate_dqi_section(site_id)
        if dqi_section:
            report.sections.append(dqi_section)
            report.key_findings.append(f"DQI Score: {site_data.get('dqi_score', 'N/A')}/100")
        
        overview_section = self._generate_overview_section(site_id, site_data)
        report.sections.append(overview_section)
        
        issues_section = self._generate_issues_section(site_id, site_data)
        report.sections.append(issues_section)
        
        if self.benchmark_engine:
            benchmark_section = self._generate_benchmark_section(site_id)
            if benchmark_section:
                report.sections.append(benchmark_section)
        
        if self.alert_engine:
            alerts = self.alert_engine.get_alerts_for_entity("site", site_id)
            if alerts:
                alert_section = ReportSection(
                    title="Active Alerts",
                    content=self._format_alerts(alerts),
                    section_type="alerts",
                    data={"count": len(alerts)}
                )
                report.sections.append(alert_section)
                report.key_findings.append(f"{len(alerts)} active alerts require attention")
        
        report.executive_summary = self._generate_executive_summary(report)
        report.recommendations = self._generate_recommendations(site_data)
        
        return report
    
    def generate_study_overview(self, study_id: str) -> Report:
        """Generate study-level overview report."""
        report = Report(
            report_id=self._generate_report_id(),
            report_type=ReportType.STUDY_OVERVIEW,
            title=f"Study Overview: {study_id}",
            entity_type="study",
            entity_id=study_id
        )
        
        study_data = self._get_study_data(study_id)
        report.raw_data = study_data
        
        report.sections.append(ReportSection(
            title="Study Metrics",
            content=self._format_study_metrics(study_data),
            section_type="metrics"
        ))
        
        if self.ranking_engine:
            from analytics import RankingMetric
            ranking = self.ranking_engine.rank_sites(RankingMetric.DQI)
            
            report.sections.append(ReportSection(
                title="Site Rankings",
                content=self._format_rankings(ranking),
                section_type="rankings"
            ))
            
            report.key_findings.append(f"Top performer: Site {ranking.top_performers[0].entity_id}" if ranking.top_performers else "No rankings available")
        
        report.executive_summary = self._generate_executive_summary(report)
        
        return report
    
    def generate_weekly_digest(self, study_id: str = None) -> Report:
        """Generate weekly digest report."""
        report = Report(
            report_id=self._generate_report_id(),
            report_type=ReportType.WEEKLY_DIGEST,
            title="Weekly Clinical Operations Digest",
            entity_type="study" if study_id else "all",
            entity_id=study_id or "all_studies",
            period_start=datetime.now().replace(hour=0, minute=0, second=0),
            period_end=datetime.now()
        )
        
        summary_stats = self._get_summary_stats(study_id)
        report.raw_data = summary_stats
        
        report.sections.append(ReportSection(
            title="Week at a Glance",
            content=self._format_weekly_summary(summary_stats),
            section_type="summary"
        ))
        
        if self.alert_engine:
            alerts = self.alert_engine.scan_all()
            critical_count = len([a for a in alerts if a.severity.value == "critical"])
            high_count = len([a for a in alerts if a.severity.value == "high"])
            
            report.sections.append(ReportSection(
                title="Alert Summary",
                content=f"**Critical:** {critical_count} | **High:** {high_count} | **Total:** {len(alerts)}",
                section_type="alerts"
            ))
            
            if critical_count > 0:
                report.key_findings.append(f"{critical_count} critical alerts require immediate attention")
        
        report.executive_summary = self._generate_executive_summary(report)
        
        return report
    
    def _get_site_data(self, site_id: str) -> Dict[str, Any]:
        node_key = f"SITE:{site_id}" if not site_id.startswith("SITE:") else site_id
        clean_id = site_id.replace("SITE:", "")
        
        if not self.graph.has_node(node_key):
            return {"site_id": clean_id, "error": "Site not found"}
        
        props = dict(self.graph.nodes[node_key])
        
        subjects = self._get_related_nodes(node_key, "Subject")
        
        dqi_score = None
        if self.dqi_calculator:
            try:
                result = self.dqi_calculator.calculate_site(clean_id)
                dqi_score = result.score
            except Exception:
                pass
        
        return {
            "site_id": clean_id,
            "total_subjects": len(subjects),
            "open_issues": int(props.get("open_issues", props.get("total_issues", 0))),
            "dqi_score": dqi_score,
            "properties": props
        }
    
    def _get_study_data(self, study_id: str) -> Dict[str, Any]:
        node_key = f"STUDY:{study_id}" if not study_id.startswith("STUDY:") else study_id
        
        if not self.graph.has_node(node_key):
            return {"study_id": study_id, "error": "Study not found"}
        
        props = dict(self.graph.nodes[node_key])
        sites = self._get_related_nodes(node_key, "Site")
        
        return {
            "study_id": study_id,
            "total_sites": len(sites),
            "total_issues": int(props.get("total_issues", 0)),
            "properties": props
        }
    
    def _get_summary_stats(self, study_id: str = None) -> Dict[str, Any]:
        sites = [n for n, d in self.graph.nodes(data=True) if d.get("node_type") == "Site"]
        subjects = [n for n, d in self.graph.nodes(data=True) if d.get("node_type") == "Subject"]
        
        total_issues = sum(
            int(self.graph.nodes[s].get("open_issues", self.graph.nodes[s].get("total_issues", 0)))
            for s in sites
        )
        
        return {
            "total_sites": len(sites),
            "total_subjects": len(subjects),
            "total_open_issues": total_issues
        }
    
    def _get_related_nodes(self, node_id: str, target_type: str) -> List[str]:
        if not self.graph.has_node(node_id):
            return []
        
        related = []
        for neighbor in list(self.graph.successors(node_id)) + list(self.graph.predecessors(node_id)):
            if self.graph.nodes.get(neighbor, {}).get("node_type") == target_type:
                related.append(neighbor)
        
        return related
    
    def _generate_dqi_section(self, site_id: str) -> Optional[ReportSection]:
        if not self.dqi_calculator:
            return None
        
        try:
            result = self.dqi_calculator.calculate_site(site_id)
            
            content_lines = [
                f"**Score:** {result.score:.1f}/100 (Grade: {result.grade})",
                f"**Status:** {result.status}",
                "",
                "### Metric Breakdown",
                ""
            ]
            
            for m in result.breakdown:
                status_icon = {"good": "âœ…", "warning": "âš ï¸", "critical": "âŒ"}.get(m.status, "")
                content_lines.append(f"- {status_icon} **{m.name.replace('_', ' ').title()}:** {m.raw_value:.2f} ({m.impact_description})")
            
            if result.top_issues:
                content_lines.append("")
                content_lines.append("### Top Issues")
                for issue in result.top_issues:
                    content_lines.append(f"- {issue}")
            
            return ReportSection(
                title="Data Quality Index (DQI)",
                content="\n".join(content_lines),
                section_type="dqi",
                data=result.to_dict()
            )
        except Exception as e:
            return None
    
    def _generate_overview_section(self, site_id: str, site_data: Dict) -> ReportSection:
        content_lines = [
            f"**Total Subjects:** {site_data.get('total_subjects', 'N/A')}",
            f"**Open Issues:** {site_data.get('open_issues', 'N/A')}",
        ]
        
        return ReportSection(
            title="Site Overview",
            content="\n".join(content_lines),
            section_type="overview"
        )
    
    def _generate_issues_section(self, site_id: str, site_data: Dict) -> ReportSection:
        issues = site_data.get("open_issues", 0)
        
        if issues == 0:
            content = "No open issues. Site is in good standing."
        elif issues < 10:
            content = f"{issues} open issues. Minor attention required."
        elif issues < 50:
            content = f"{issues} open issues. Moderate intervention recommended."
        else:
            content = f"âš ï¸ {issues} open issues. **Immediate attention required.**"
        
        return ReportSection(
            title="Issue Summary",
            content=content,
            section_type="issues"
        )
    
    def _generate_benchmark_section(self, site_id: str) -> Optional[ReportSection]:
        if not self.benchmark_engine:
            return None
        
        try:
            benchmark = self.benchmark_engine.benchmark_site(site_id)
            
            content_lines = [
                f"**Overall Percentile:** {benchmark.overall_percentile:.0f}th",
                f"**Performance Level:** {benchmark.overall_performance.value.replace('_', ' ').title()}",
                f"**Study Rank:** {benchmark.study_rank}/{benchmark.study_total}" if benchmark.study_rank else "",
                "",
            ]
            
            if benchmark.strengths:
                content_lines.append(f"**Strengths:** {', '.join(benchmark.strengths)}")
            if benchmark.weaknesses:
                content_lines.append(f"**Areas for Improvement:** {', '.join(benchmark.weaknesses)}")
            
            return ReportSection(
                title="Peer Comparison",
                content="\n".join(content_lines),
                section_type="benchmark"
            )
        except Exception:
            return None
    
    def _format_alerts(self, alerts: List) -> str:
        if not alerts:
            return "No active alerts."
        
        lines = []
        for alert in alerts[:5]:
            severity_icon = {"critical": "ðŸ”´", "high": "ðŸŸ ", "medium": "ðŸŸ¡", "low": "ðŸŸ¢"}.get(alert.severity.value, "âšª")
            lines.append(f"{severity_icon} **{alert.title}**")
            lines.append(f"   {alert.description}")
            lines.append("")
        
        if len(alerts) > 5:
            lines.append(f"*... and {len(alerts) - 5} more alerts*")
        
        return "\n".join(lines)
    
    def _format_study_metrics(self, study_data: Dict) -> str:
        lines = [
            f"**Total Sites:** {study_data.get('total_sites', 'N/A')}",
            f"**Total Issues:** {study_data.get('total_issues', 'N/A')}",
        ]
        return "\n".join(lines)
    
    def _format_rankings(self, ranking) -> str:
        if not ranking.rankings:
            return "No ranking data available."
        
        lines = ["| Rank | Site | Score |", "|------|------|-------|"]
        for r in ranking.rankings[:10]:
            lines.append(f"| {r.rank} | {r.entity_id} | {r.value:.1f} |")
        
        return "\n".join(lines)
    
    def _format_weekly_summary(self, stats: Dict) -> str:
        lines = [
            f"**Active Sites:** {stats.get('total_sites', 'N/A')}",
            f"**Active Subjects:** {stats.get('total_subjects', 'N/A')}",
            f"**Total Open Issues:** {stats.get('total_open_issues', 'N/A')}",
        ]
        return "\n".join(lines)
    
    def _generate_executive_summary(self, report: Report) -> str:
        if not self.llm:
            findings = "; ".join(report.key_findings) if report.key_findings else "No major findings"
            return f"This report provides an overview of {report.entity_type} {report.entity_id}. Key findings: {findings}"
        
        sections_text = "\n".join([f"- {s.title}: {s.content[:200]}" for s in report.sections[:5]])
        
        prompt = f"""Generate a 2-3 sentence executive summary for this clinical trial report:

Report Type: {report.report_type.value}
Entity: {report.entity_type} {report.entity_id}

Sections:
{sections_text}

Key Findings: {', '.join(report.key_findings) if report.key_findings else 'None identified'}

Be concise and actionable."""
        
        try:
            # Use thread executor with timeout to prevent blocking async server
            import concurrent.futures
            with concurrent.futures.ThreadPoolExecutor(max_workers=1) as executor:
                future = executor.submit(self.llm.invoke, prompt)
                try:
                    response = future.result(timeout=30)  # 30 second timeout
                    return response.content
                except concurrent.futures.TimeoutError:
                    return f"This report summarizes the status of {report.entity_type} {report.entity_id}."
        except Exception:
            return f"This report summarizes the status of {report.entity_type} {report.entity_id}."
    
    def _generate_recommendations(self, data: Dict) -> List[str]:
        recommendations = []
        
        open_issues = data.get("open_issues", 0)
        if open_issues > 50:
            recommendations.append("Prioritize issue resolution - schedule dedicated data cleaning sessions")
        elif open_issues > 20:
            recommendations.append("Review and categorize open issues for efficient resolution")
        
        dqi_score = data.get("dqi_score")
        if dqi_score and dqi_score < 60:
            recommendations.append("Conduct detailed data quality review to identify root causes")
        
        if not recommendations:
            recommendations.append("Maintain current monitoring practices")
        
        return recommendations
